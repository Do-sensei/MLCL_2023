{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the data list of the airb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "airb_dir = os.path.join(data_dir, 'airb')\n",
    "print(os.listdir(airb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airb_csv = os.path.join(airb_dir, 'AirBNBReviews.csv')\n",
    "print(airb_csv)\n",
    "print(\"Check in csv file: \", os.path.isfile(airb_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airb_df = pd.read_csv(airb_csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airb_df.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airb_df.groupby(['Genre', 'Positive or Negative']).size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is your DataFrame and it has columns 'Genre' and 'Positive or Negative'\n",
    "airb_df.groupby(['Genre', 'Positive or Negative']).size().unstack().plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Clouds\n",
    "Word clouds can give you a visual representation of the most frequently used words in your dataset. The more a specific word appears in your text, the bigger and bolder it appears in the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's assume 'data' is your DataFrame and it has a column 'Review'\n",
    "text = ' '.join(review for review in airb_df.Review)\n",
    "wordcloud = WordCloud(background_color='white').generate(text)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the above the error!!\n",
    "    - why the error is occured?\n",
    "    - how to solve the error?\n",
    "    - ***Check the data Right Now!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airb_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's assume 'data' is your DataFrame and it has a column 'Review'\n",
    "airb_df['Review'] = airb_df['Review'].fillna('') # resolve the NaN issue\n",
    "text = ' '.join(review for review in airb_df.Review)\n",
    "wordcloud = WordCloud(background_color='white').generate(text)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# First, we'll replace NaNs with empty strings just in case\n",
    "airb_df['Review'] = airb_df['Review'].fillna('')\n",
    "\n",
    "# Define your own set of stopwords, or use the one provided by WordCloud\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Update the set of stopwords with any additional words you want to ignore\n",
    "# For example, if you want to ignore the words 'the' and 'and', you would do:\n",
    "# stopwords.update(['the', 'and'])\n",
    "\n",
    "def generate_wordcloud(reviews):\n",
    "    text = ' '.join(review for review in reviews)\n",
    "    # wordcloud = WordCloud(stopwords=stopwords, background_color='white').generate(text)\n",
    "    wordcloud = WordCloud(stopwords=stopwords, background_color='white', random_state=1502).generate(text)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'airb_df' is your DataFrame and it has columns 'Review' and 'Positive or Negative'\n",
    "positive_reviews = airb_df[airb_df['Positive or Negative'] == 1]['Review']\n",
    "negative_reviews = airb_df[airb_df['Positive or Negative'] == 0]['Review']\n",
    "\n",
    "print(\"Word cloud for positive reviews\")\n",
    "generate_wordcloud(positive_reviews)\n",
    "\n",
    "print(\"Word cloud for negative reviews\")\n",
    "generate_wordcloud(negative_reviews)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Review Lengths\n",
    "\n",
    "This can give you an idea of the distribution of the lengths of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airb_df['Review'].str.len().hist()\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie Chart of Sentiment Distribution:\n",
    "\n",
    "This will give a good view of the data balance between positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airb_df['Positive or Negative'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap of Term Frequency\n",
    "\n",
    " You could create a document-term matrix and then plot a heatmap to visualize the frequency of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(airb_df['Review'])\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "frequency = X.toarray().sum(axis=0)\n",
    "\n",
    "df = pd.DataFrame(frequency, index=terms, columns=[\"Frequency\"])\n",
    "\n",
    "# Top 20 frequent terms\n",
    "top_terms = df.sort_values(by=\"Frequency\", ascending=False).head(20)\n",
    "\n",
    "sns.heatmap(top_terms, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select Model for Sentiment Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use the Bert Model for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw text: ', airb_df['Review'][0])\n",
    "print('Tokenized: ', tokenizer.tokenize(airb_df['Review'][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode The Review Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(airb_df['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokens for the first review: \", tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"]))\n",
    "print(\"Token IDs for the first review: \", encoded_input[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# If you want to print only a part of the vocabulary (e.g., the first 10 items), you can do:\n",
    "for i, (token, token_id) in enumerate(vocab.items()):\n",
    "    print(token, token_id)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_token = {id: token for token, id in vocab.items()}\n",
    "\n",
    "# Replace 1012 with the ID you want to look up\n",
    "token = id_to_token[1012]\n",
    "print(\"Token for ID 1012:\", token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode the Reviews from Tokens to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_review = encoded_input[\"input_ids\"]\n",
    "print(\"Token IDs for the first review: \",encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_review = tokenizer.decode(encoded_review)\n",
    "print(\"Decoded review: \", decoded_review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(airb_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of training data: \", len(train_data))\n",
    "print(\"Length of test data: \", len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
